{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN6XQOJWOiM255K8WWKIthZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ji-hun-choi/SOTA-Study/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG1fuKHaxhFz",
        "outputId": "189f73d3-e151-4e41-fd35-a01bbe0bfaa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 3.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece, einops\n",
            "Successfully installed einops-0.4.1 sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install einops sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "6ZV8itWqyBca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from einops import rearrange, reduce, repeat\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import joblib\n",
        "import gc\n",
        "import os"
      ],
      "metadata": {
        "id": "n7S1KONzxl4C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "kgvS3LVWx_xr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2\n",
        "HIDDEN_DIM = 256\n",
        "NUM_HEAD = 8 \n",
        "INNER_DIM = 512\n",
        "\n",
        "PAD_IDX = 0\n",
        "EOS_IDX = 3"
      ],
      "metadata": {
        "id": "bROerRSmyMiy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "## google drive에서 압축된 dataset download\n",
        "url = 'https://drive.google.com/uc?id=1vZ_bjYf4mKj0NUUbYfShcBOdHBP24boX'\n",
        "fname = 'Downloads.zip'\n",
        "gdown.download(url, fname, quiet=False)\n",
        "!unzip Downloads.zip -d Downloads # test를 위한 data.zip 파일 가져오기."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgDOOP6d4hfC",
        "outputId": "dd26e544-9583-4c1b-88f0-0cffcd92eb72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vZ_bjYf4mKj0NUUbYfShcBOdHBP24boX\n",
            "To: /content/Downloads.zip\n",
            "100%|██████████| 7.68M/7.68M [00:00<00:00, 91.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Downloads.zip\n",
            "  inflating: Downloads/src_train.pkl  \n",
            "  inflating: Downloads/trg_list.pkl  \n",
            "  inflating: Downloads/trg_train.pkl  \n",
            "  inflating: Downloads/src_list.pkl  \n",
            "  inflating: Downloads/src_valid.pkl  \n",
            "  inflating: Downloads/trg_valid.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load Dataset"
      ],
      "metadata": {
        "id": "_x0z01Gv6fPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddir = '/content/Downloads'\n",
        "\n",
        "src_train_path = os.path.join(ddir, 'src_train.pkl')\n",
        "src_valid_path = os.path.join(ddir, 'src_valid.pkl')\n",
        "trg_train_path = os.path.join(ddir, 'trg_train.pkl')\n",
        "trg_valid_path = os.path.join(ddir, 'trg_valid.pkl')"
      ],
      "metadata": {
        "id": "sGiecCC4yRl4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_train = joblib.load(src_train_path) \n",
        "src_valid = joblib.load(src_valid_path) \n",
        "trg_train = joblib.load(trg_train_path)  \n",
        "trg_valid = joblib.load(trg_valid_path) "
      ],
      "metadata": {
        "id": "pCAOOt-85iqN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 확인"
      ],
      "metadata": {
        "id": "6lOVViUO6g4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_valid)"
      ],
      "metadata": {
        "id": "0iSR1B7H5070"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloads"
      ],
      "metadata": {
        "id": "Pp2H73zw8FKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "SEQ_LEN = 50\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "x3qpAYUe7_6V"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, src_data, trg_data):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(src_data) == len(trg_data)\n",
        "\n",
        "        self.src_data = src_data\n",
        "        self.trg_data = trg_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_data[idx]\n",
        "        trg_input = self.trg_data[idx]\n",
        "        trg_output = trg_input[1:SEQ_LEN]\n",
        "        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values=0)\n",
        "\n",
        "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
        "\n",
        "train_dataset = TrainDataset(src_train, trg_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "T9bu57Y56kKN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidDataset(Dataset):\n",
        "    def __init__(self, src_data, trg_data):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(src_data) == len(trg_data)\n",
        "\n",
        "        self.src_data = src_data\n",
        "        self.trg_data = trg_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_data[idx]\n",
        "        trg_input = self.trg_data[idx]\n",
        "        trg_output = trg_input[1:SEQ_LEN]\n",
        "        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values=0)\n",
        "\n",
        "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
        "\n",
        "valid_dataset = ValidDataset(src_train, trg_train)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "7egRHVdb9ZGn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "pHKSdc_z-Dk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, N=2, hidden_dim=256, num_head=8, inner_dim=512):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(N, hidden_dim, num_head, inner_dim)\n",
        "        self.decoder = Decoder(N, hidden_dim, num_head, inner_dim)\n",
        "\n",
        "    def forward(self, enc_src, dec_src):\n",
        "        enc_output = self.encoder(enc_src)\n",
        "        logits, output = self.decoder(dec_src, enc_src, enc_output)\n",
        "\n",
        "        return logits, output"
      ],
      "metadata": {
        "id": "zZ2fACbQ9m32"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "k_Srk8k-_fto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__ (self, N, hidden_dim, num_head, inner_dim,max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        # N : number of encoder layer repeated \n",
        "        self.N = N\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_head = num_head\n",
        "        self.inner_dim = inner_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "        self.enc_layers = nn.ModuleList([EncoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \n",
        "        batch_size = input.shape[0]\n",
        "        seq_len = input.shape[1]\n",
        "\n",
        "\n",
        "        mask = makeMask(input, option='padding')\n",
        "\n",
        "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "\n",
        "        output = self.dropout(self.embedding(input) + self.pos_embedding(pos))\n",
        "\n",
        "        # Dropout\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        # N encoder layer\n",
        "        for layer in self.enc_layers:\n",
        "            output = layer(output, mask)\n",
        "\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "visBxYrv_J6V"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_head = num_head\n",
        "        self.inner_dim = inner_dim\n",
        "        \n",
        "        self.multiheadattention = Multiheadattention(hidden_dim, num_head)\n",
        "        self.ffn = FFN(hidden_dim, inner_dim)\n",
        "        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.dropout2 = nn.Dropout(p=0.1)\n",
        "\n",
        "\n",
        "    def forward(self, input, mask = None):\n",
        "\n",
        "        output = self.multiheadattention(srcQ= input, srcK = input, srcV = input, mask = mask)\n",
        "        output = self.dropout1(output)\n",
        "        output = input + output\n",
        "        output = self.layerNorm1(output)\n",
        "\n",
        "        output_ = self.ffn(output)\n",
        "        output_ = self.dropout2(output_)\n",
        "        output = output + output_\n",
        "        output = self.layerNorm2(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "KAtSAQ9U_bgO"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## class Multiheadattention"
      ],
      "metadata": {
        "id": "EduK032b_jHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Multiheadattention(nn.Module):\n",
        "    def __init__(self, hidden_dim: int, num_head: int):\n",
        "        super().__init__()\n",
        "\n",
        "        # embedding_dim, d_model, 512 in paper\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # 8 in paper\n",
        "        self.num_head = num_head\n",
        "        # head_dim, d_key, d_query, d_value, 64 in paper (= 512 / 8)\n",
        "        self.head_dim = hidden_dim // num_head\n",
        "        self.scale = torch.sqrt(torch.FloatTensor()).to(device)\n",
        "\n",
        "        self.fcQ = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fcK = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fcV = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fcOut = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "\n",
        "    def forward(self, srcQ, srcK, srcV, mask=None):\n",
        "\n",
        "        ##### SCALED DOT PRODUCT ATTENTION ######\n",
        "\n",
        "        Q = self.fcQ(srcQ)\n",
        "        K = self.fcK(srcK)\n",
        "        V = self.fcV(srcV)\n",
        "\n",
        "        Q = rearrange(\n",
        "            Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
        "        K_T = rearrange(\n",
        "            K, 'bs seq_len (num_head head_dim) -> bs num_head head_dim seq_len', num_head=self.num_head)\n",
        "        V = rearrange(\n",
        "            V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
        "        \n",
        "        attention_energy = torch.matmul(Q, K_T)\n",
        "\n",
        "        if mask is not None :\n",
        " \n",
        "            attention_energy = torch.masked_fill(attention_energy, (mask == 0), -1e+4)\n",
        "            \n",
        "        attention_energy = torch.softmax(attention_energy, dim = -1)\n",
        "\n",
        "        result = torch.matmul(self.dropout(attention_energy),V)\n",
        "\n",
        "        ##### END OF SCALED DOT PRODUCT ATTENTION ######\n",
        "\n",
        "        # CONCAT\n",
        "        result = rearrange(result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n",
        "\n",
        "        result = self.fcOut(result)\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "jnRKltDB_jd8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FFN"
      ],
      "metadata": {
        "id": "phWLaAVJ_mGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__ (self, hidden_dim, inner_dim):\n",
        "        super().__init__()\n",
        " \n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.inner_dim = inner_dim \n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim, inner_dim)\n",
        "        self.fc2 = nn.Linear(inner_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "   \n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = self.fc1(output)\n",
        "        output2 = self.relu(output)\n",
        "        output2 = self.dropout(output)\n",
        "        output3 = self.fc2(output2)\n",
        "\n",
        "        return output3"
      ],
      "metadata": {
        "id": "PrsJBs0W_lDN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "Xwbb4zJz_pzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__ (self, N, hidden_dim, num_head, inner_dim, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        # N : number of encoder layer repeated \n",
        "        self.N = N\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_head = num_head\n",
        "        self.inner_dim = inner_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.dec_layers = nn.ModuleList([DecoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        \n",
        "        self.finalFc = nn.Linear(hidden_dim, VOCAB_SIZE)\n",
        "\n",
        "\n",
        "    def forward(self, input, enc_src, enc_output):\n",
        "\n",
        "        \n",
        "        lookaheadMask = makeMask(input, option= 'lookahead')\n",
        "        paddingMask = makeMask(enc_src, option = 'padding')\n",
        "\n",
        "        # embedding layer\n",
        "        output = self.embedding(input)\n",
        "\n",
        "        # Dropout\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        for layer in self.dec_layers:\n",
        "            output = layer(output, enc_output, paddingMask, lookaheadMask)\n",
        "\n",
        "        logits = self.finalFc(output)\n",
        "\n",
        "        output = torch.softmax(logits, dim = -1)\n",
        "\n",
        "        output = torch.argmax(output, dim = -1)\n",
        "\n",
        "\n",
        "        return logits, output"
      ],
      "metadata": {
        "id": "AixuE6-__og9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.inner_dim = inner_dim\n",
        "\n",
        "        self.multiheadattention1 = Multiheadattention(hidden_dim, num_head)\n",
        "        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.multiheadattention2 = Multiheadattention(hidden_dim, num_head)\n",
        "        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.ffn = FFN(hidden_dim, inner_dim)\n",
        "        self.layerNorm3 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.dropout2 = nn.Dropout(p=0.1)\n",
        "        self.dropout3 = nn.Dropout(p=0.1)\n",
        "\n",
        "    \n",
        "    def forward(self, input, enc_output, paddingMask, lookaheadMask):\n",
        "\n",
        "        # first multiheadattention\n",
        "        output = self.multiheadattention1(input, input, input, lookaheadMask)\n",
        "        output = self.dropout1(output)\n",
        "        output = output + input\n",
        "        output = self.layerNorm1(output)\n",
        "\n",
        "\n",
        "        # second multiheadattention\n",
        "        output_ = self.multiheadattention2(output, enc_output, enc_output, paddingMask)\n",
        "        output_ = self.dropout2(output_)\n",
        "        output = output_ + output\n",
        "        output = self.layerNorm2(output)\n",
        "\n",
        "\n",
        "        # Feedforward Network\n",
        "        output_ = self.ffn(output)\n",
        "        output_ = self.dropout3(output_)\n",
        "        output = output + output_\n",
        "        output = self.layerNorm3(output)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "rv99yu6B_qxN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeMask(tensor, option: str) -> torch.Tensor:\n",
        "  \n",
        "    if option == 'padding':\n",
        "        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device)\n",
        "       \n",
        "        mask = (tensor != tmp).float()\n",
        "        \n",
        "        mask = rearrange(mask, 'bs seq_len -> bs 1 1 seq_len ')\n",
        "\n",
        "    elif option == 'lookahead':\n",
        "\n",
        "        padding_mask = makeMask(tensor, 'padding')\n",
        "        padding_mask = repeat(\n",
        "            padding_mask, 'bs 1 1 k_len -> bs 1 new k_len', new=padding_mask.shape[3])\n",
        "        \n",
        "        mask = torch.ones_like(padding_mask)\n",
        "        mask = torch.tril(mask)\n",
        "\n",
        "        mask = mask * padding_mask\n",
        "        \n",
        "    return mask"
      ],
      "metadata": {
        "id": "DIup7oXd_r9l"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 생성"
      ],
      "metadata": {
        "id": "c_tA5_zN_tLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)"
      ],
      "metadata": {
        "id": "T8VOEA8vBUm1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-4, weight_decay = 0)\n",
        "\n",
        "def criterion(logits: torch.tensor, targets: torch.tensor):\n",
        "    return nn.CrossEntropyLoss(ignore_index=PAD_IDX)(logits.view(-1,VOCAB_SIZE), targets.view(-1))"
      ],
      "metadata": {
        "id": "k64JN-YbBVoH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Function"
      ],
      "metadata": {
        "id": "jehR9YMxBkbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0\n",
        "    running_accuracy = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (src, trg_input, trg_output) in bar:\n",
        "        src = src.to(device)\n",
        "        trg_input = trg_input.to(device)\n",
        "        trg_output = trg_output.to(device)\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        logits, output = model(enc_src=src, dec_src=trg_input)\n",
        "        loss = criterion(logits, trg_output)\n",
        "\n",
        "        loss.backward()\n",
        "    \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)  \n",
        "     \n",
        "        optimizer.step()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # change learning rate by Scheduler\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        running_loss += loss.item() * batch_size\n",
        "        running_accuracy = np.mean(\n",
        "            output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
        "\n",
        "        accuracy += running_accuracy\n",
        "\n",
        "        dataset_size += batch_size\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / np.float(\n",
        "                step+1)\n",
        "        )\n",
        "\n",
        "    accuracy /= len(dataloader)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return epoch_loss, accuracy"
      ],
      "metadata": {
        "id": "YlcGfSdbBnMt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valid Function"
      ],
      "metadata": {
        "id": "PA1hPQSLBna9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (src, trg_input, trg_output) in bar:\n",
        "        src = src.to(device)\n",
        "        trg_input = trg_input.to(device)\n",
        "        trg_output = trg_output.to(device)\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        logits, output = model(enc_src = src, dec_src = trg_input)\n",
        "        loss = criterion(logits, trg_output)\n",
        "\n",
        "        running_loss += loss.item() * batch_size\n",
        "        dataset_size += batch_size\n",
        "\n",
        "     \n",
        "        val_loss = running_loss / dataset_size\n",
        "        running_accuracy = np.mean(output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
        "        \n",
        "        accuracy += running_accuracy\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy = accuracy / np.float(step + 1)\n",
        "        )\n",
        "\n",
        "    accuracy /= len(dataloader)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return val_loss, accuracy"
      ],
      "metadata": {
        "id": "iXxFVlsIBsrN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "-VjovVjDBunl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    num_epochs,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=True,\n",
        "    early_stopping_step=10,\n",
        "):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        gc.collect()\n",
        "\n",
        "        train_epoch_loss, train_accuracy = train_one_epoch(\n",
        "            model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            dataloader= train_dataloader,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "        )\n",
        "\n",
        "        val_loss, val_accuracy = valid_one_epoch(\n",
        "            model, valid_dataloader, device=device, epoch=epoch\n",
        "        )\n",
        "\n",
        "        history[f\"{metric_prefix}Train Loss\"].append(train_epoch_loss)\n",
        "        history[f\"{metric_prefix}Train Accuracy\"].append(train_accuracy)\n",
        "        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n",
        "        history[f\"{metric_prefix}Valid Accuracy\"].append(val_accuracy)\n",
        "\n",
        "\n",
        "        print(f\"Valid Loss : {val_loss}\")\n",
        "\n",
        "        if val_loss <= best_loss:\n",
        "            early_stop_counter = 0\n",
        "\n",
        "            print(\n",
        "                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n",
        "            )\n",
        "\n",
        "            # Update Best Loss\n",
        "            best_loss = val_loss\n",
        "            \n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(file_prefix, epoch, best_loss)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            torch.save(model.state_dict(), f\"{file_prefix}best_{epoch}epoch.bin\")\n",
        "\n",
        "            print(f\"Model Saved\")\n",
        "\n",
        "        elif early_stopping:\n",
        "            early_stop_counter += 1\n",
        "            if early_stop_counter > early_stopping_step:\n",
        "                break\n",
        "        \n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print(\n",
        "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n",
        "            time_elapsed // 3600,\n",
        "            (time_elapsed % 3600) // 60,\n",
        "            (time_elapsed % 3600) % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "26-Pms9oBvld"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training 시작"
      ],
      "metadata": {
        "id": "DPCtBt95BxGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(\n",
        "    model = model,\n",
        "    optimizer = optimizer,\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5),\n",
        "    device = device,\n",
        "    num_epochs = 2000,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=True,\n",
        "    early_stopping_step=10,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "i6FPAr3BBzrX",
        "outputId": "af0ee876-3284-46a4-f754-6b7fd0b0461b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU:Tesla P100-PCIE-16GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/389 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1d3ec80f0558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mearly_stopping_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-56-087663d34a55>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs, metric_prefix, file_prefix, early_stopping, early_stopping_step)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-56aa3ff10f88>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [28] at entry 0 and [21] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'final.bin')"
      ],
      "metadata": {
        "id": "pDc2dmpfB1KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load text data"
      ],
      "metadata": {
        "id": "BFgYEk3EEbmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "RPqZJsZbE7Bn"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "## google drive에서 압축된 dataset download\n",
        "url = 'https://drive.google.com/uc?id=1A7awcIZP_GlFAZm83q-xdEMTFOkf8zR_'\n",
        "fname = 'korean-parallel-corpora.zip'\n",
        "gdown.download(url, fname, quiet=False)\n",
        "!unzip korean-parallel-corpora.zip # test를 위한 data.zip 파일 가져오기."
      ],
      "metadata": {
        "id": "TVyNzkYOFNoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/korean-parallel-corpora/bible/'"
      ],
      "metadata": {
        "id": "j5JVTivVE8P3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_train = open(os.path.join(DATASET_PATH, 'bible-all.en.txt'))\n",
        "en_train_content = en_train.read()\n",
        "\n",
        "en_train_list = en_train_content.split('\\n')"
      ],
      "metadata": {
        "id": "6WjVyT9gFVlv"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ko_train = open(os.path.join(DATASET_PATH, 'bible-all.kr.txt'))\n",
        "ko_train_content = ko_train.read()\n",
        "\n",
        "ko_train_list = ko_train_content.split('\\n')"
      ],
      "metadata": {
        "id": "bgVLkUA3FYU3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_train_list[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R-M_ujNFZvf",
        "outputId": "293d5b35-45a9-49b7-fc3d-2255df2f65ae"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Genesis1.1  In the beginning God created the heavens and the earth.',\n",
              " 'Genesis1.2  Now the earth was formless and empty, darkness was over the surface of the deep, and the Spirit of God was hovering over the waters.',\n",
              " 'Genesis1.3  And God said, \"Let there be light,\" and there was light.',\n",
              " 'Genesis1.4  God saw that the light was good, and He separated the light from the darkness.',\n",
              " 'Genesis1.5  God called the light \"day,\" and the darkness he called \"night.\" And there was evening, and there was morning--the first day.',\n",
              " 'Genesis1.6  And God said, \"Let there be an expanse between the waters to separate water from water.\"',\n",
              " 'Genesis1.7  So God made the expanse and separated the water under the expanse from the water above it. And it was so.',\n",
              " 'Genesis1.8  God called the expanse \"sky.\" And there was evening, and there was morning--the second day.',\n",
              " 'Genesis1.9  And God said, \"Let the water under the sky be gathered to one place, and let dry ground appear.\" And it was so.',\n",
              " 'Genesis1.10  God called the dry ground \"land,\" and the gathered waters he called \"seas.\" And God saw that it was good.']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame()\n",
        "data['en_raw'] = en_train_list\n",
        "data['ko_raw'] = ko_train_list"
      ],
      "metadata": {
        "id": "9IMt5Zc3Faw2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KcEZEwa_FcA2",
        "outputId": "342ccf65-173b-4451-dfd2-3598113fcd20"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              en_raw  \\\n",
              "0  Genesis1.1  In the beginning God created the h...   \n",
              "1  Genesis1.2  Now the earth was formless and emp...   \n",
              "2  Genesis1.3  And God said, \"Let there be light,...   \n",
              "3  Genesis1.4  God saw that the light was good, a...   \n",
              "4  Genesis1.5  God called the light \"day,\" and th...   \n",
              "\n",
              "                                              ko_raw  \n",
              "0                    Genesis1.1  태초에 하나님이 천지를 창조하셨다.  \n",
              "1  Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...  \n",
              "2      Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n",
              "3   Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n",
              "4  Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b54b8db3-3b41-43de-95f2-31dcf85c18eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_raw</th>\n",
              "      <th>ko_raw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Genesis1.1  In the beginning God created the h...</td>\n",
              "      <td>Genesis1.1  태초에 하나님이 천지를 창조하셨다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Genesis1.2  Now the earth was formless and emp...</td>\n",
              "      <td>Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Genesis1.3  And God said, \"Let there be light,...</td>\n",
              "      <td>Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Genesis1.4  God saw that the light was good, a...</td>\n",
              "      <td>Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Genesis1.5  God called the light \"day,\" and th...</td>\n",
              "      <td>Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b54b8db3-3b41-43de-95f2-31dcf85c18eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b54b8db3-3b41-43de-95f2-31dcf85c18eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b54b8db3-3b41-43de-95f2-31dcf85c18eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g69RG7WtFdTX",
        "outputId": "dded2211-8fd5-48f0-f270-35c79be9405e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31104"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.reset_index(drop = True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rGb-P03vFeK4",
        "outputId": "c60faccb-ed7d-4e0f-9ca7-d132e92f1734"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              en_raw  \\\n",
              "0  Genesis1.1  In the beginning God created the h...   \n",
              "1  Genesis1.2  Now the earth was formless and emp...   \n",
              "2  Genesis1.3  And God said, \"Let there be light,...   \n",
              "3  Genesis1.4  God saw that the light was good, a...   \n",
              "4  Genesis1.5  God called the light \"day,\" and th...   \n",
              "\n",
              "                                              ko_raw  \n",
              "0                    Genesis1.1  태초에 하나님이 천지를 창조하셨다.  \n",
              "1  Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...  \n",
              "2      Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n",
              "3   Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n",
              "4  Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-572b187d-4054-40d9-ac05-eb00ceb3be61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_raw</th>\n",
              "      <th>ko_raw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Genesis1.1  In the beginning God created the h...</td>\n",
              "      <td>Genesis1.1  태초에 하나님이 천지를 창조하셨다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Genesis1.2  Now the earth was formless and emp...</td>\n",
              "      <td>Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Genesis1.3  And God said, \"Let there be light,...</td>\n",
              "      <td>Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Genesis1.4  God saw that the light was good, a...</td>\n",
              "      <td>Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Genesis1.5  God called the light \"day,\" and th...</td>\n",
              "      <td>Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-572b187d-4054-40d9-ac05-eb00ceb3be61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-572b187d-4054-40d9-ac05-eb00ceb3be61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-572b187d-4054-40d9-ac05-eb00ceb3be61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['en'] = data['en_raw'].apply(lambda x: x.split(' ')[1:])\n",
        "data['en'] = data['en'].apply(lambda x: (' ').join(x))\n",
        "data['ko'] = data['ko_raw'].apply(lambda x: x.split(' ')[1:])\n",
        "data['ko'] = data['ko'].apply(lambda x: (' ').join(x))"
      ],
      "metadata": {
        "id": "YEiZGVcyFfG_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['en','ko']]\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z8NWDve-FgUv",
        "outputId": "1a35b40f-ec90-4b89-f8f3-43d135ef1e40"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  en  \\\n",
              "0   In the beginning God created the heavens and ...   \n",
              "1   Now the earth was formless and empty, darknes...   \n",
              "2   And God said, \"Let there be light,\" and there...   \n",
              "3   God saw that the light was good, and He separ...   \n",
              "4   God called the light \"day,\" and the darkness ...   \n",
              "\n",
              "                                                  ko  \n",
              "0                                태초에 하나님이 천지를 창조하셨다.  \n",
              "1   땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...  \n",
              "2                  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n",
              "3               그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n",
              "4   빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b467c840-03fb-45c1-a449-12b757109758\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ko</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the beginning God created the heavens and ...</td>\n",
              "      <td>태초에 하나님이 천지를 창조하셨다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now the earth was formless and empty, darknes...</td>\n",
              "      <td>땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And God said, \"Let there be light,\" and there...</td>\n",
              "      <td>하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>God saw that the light was good, and He separ...</td>\n",
              "      <td>그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>God called the light \"day,\" and the darkness ...</td>\n",
              "      <td>빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b467c840-03fb-45c1-a449-12b757109758')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b467c840-03fb-45c1-a449-12b757109758 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b467c840-03fb-45c1-a449-12b757109758');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHT_FILE = 'final.bin'\n",
        "WEIGHT_PATH = '/content/'\n",
        "\n",
        "model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)\n",
        "model.load_state_dict(torch.load(os.path.join(WEIGHT_PATH, WEIGHT_FILE), map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgZB_oOWFhM_",
        "outputId": "7c869b60-7413-48b5-ba10-8a7232304bb5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(10000, 256, padding_idx=0)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (enc_layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (multiheadattention): Multiheadattention(\n",
              "          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ffn): FFN(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (multiheadattention): Multiheadattention(\n",
              "          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ffn): FFN(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(10000, 256, padding_idx=0)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (dec_layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (multiheadattention1): Multiheadattention(\n",
              "          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (multiheadattention2): Multiheadattention(\n",
              "          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (multiheadattention1): Multiheadattention(\n",
              "          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (multiheadattention2): Multiheadattention(\n",
              "          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layerNorm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (finalFc): Linear(in_features=256, out_features=10000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "SRC_MODEL_FILE = os.path.join(ddir,'src.model')\n",
        "TRG_MODEL_FILE = os.path.join(ddir,'trg.model')\n",
        "\n",
        "sp_src = spm.SentencePieceProcessor()\n",
        "sp_src.Load(SRC_MODEL_FILE)\n",
        "sp_trg = spm.SentencePieceProcessor()\n",
        "sp_trg.Load(TRG_MODEL_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ivbMXQB0F0bv",
        "outputId": "992e3074-b948-4a63-8663-bc685536a09a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-0439a88b8bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msp_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msp_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msp_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msp_trg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRG_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mLoad\u001b[0;34m(self, model_file, model_proto)\u001b[0m\n\u001b[1;32m    903\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodel_proto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromSerializedProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mLoadFromFile\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor_LoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_EncodeAsIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_sampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_bos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_eos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memit_unk_piece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Not found: \"/content/Downloads/src.model\": No such file or directory Error #2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJrikSnbF3j-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}